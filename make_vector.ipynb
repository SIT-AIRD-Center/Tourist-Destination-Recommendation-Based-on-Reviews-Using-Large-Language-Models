{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from my_utils import *\n",
    "from sentence_luke_japanese import SentenceLukeJapanese\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_luke = SentenceLukeJapanese()\n",
    "vector_length = model_luke.encode(\"このパソコン終わってます\")[0].shape[0]\n",
    "\n",
    "#\n",
    "model_luke.encode(\"このパソコン終わってます\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dir = \"jalan_review3/\"\n",
    "target_dir = \"jalan_review_aligned_v3/\"\n",
    "if os.path.exists(target_dir):\n",
    "    shutil.rmtree(target_dir)\n",
    "os.mkdir(target_dir)\n",
    "\n",
    "min_reviews = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [35:31<00:00, 125.38s/it, name=照葉大吊橋, category=近代建築, prefecture=宮崎県, num_review=162]                                                                            \n"
     ]
    }
   ],
   "source": [
    "category_counts = dict()\n",
    "category_vectors = dict()\n",
    "prefecture_counts = dict()\n",
    "prefecture_vectors = dict()\n",
    "\n",
    "weighted_category_counts = dict()\n",
    "weighted_category_vectors = dict()\n",
    "weighted_prefecture_counts = dict()\n",
    "weighted_prefecture_vectors = dict()\n",
    "\n",
    "progress_bar = tqdm(os.listdir(review_dir))\n",
    "for C in progress_bar:\n",
    "    tmp_dir = f\"{review_dir}{C}/\"\n",
    "    tmp_paths = [tmp_dir + TP for TP in os.listdir(tmp_dir)]\n",
    "\n",
    "    for P in tmp_paths:\n",
    "        if \"last_page\" in P: \n",
    "            continue\n",
    "\n",
    "        with open(P, \"r\") as f:\n",
    "            a = json.load(f)\n",
    "        \n",
    "        if len(a[\"reviews\"]) < min_reviews:\n",
    "            continue\n",
    "\n",
    "        name = a[\"name\"].replace(\"\\\"\", \"\")\n",
    "        category = C\n",
    "        prefecture = extract_prefecture(a[\"adress\"])\n",
    "\n",
    "        if prefecture == None:\n",
    "            continue\n",
    "\n",
    "        progress_bar.set_postfix({\"name\" : name,\n",
    "                                  \"category\" : category,\n",
    "                                  \"prefecture\" : prefecture,\n",
    "                                  \"num_review\" : len(a[\"reviews\"])},\n",
    "                                  refresh=True)\n",
    "\n",
    "        spt_vector = np.zeros(shape = (vector_length))\n",
    "\n",
    "        batch_size = 256\n",
    "        for i in range(0, len(a[\"reviews\"]), batch_size):\n",
    "            last_idx = min(i + batch_size, len(a[\"reviews\"]))\n",
    "            tmp = [A[\"review\"] for A in a[\"reviews\"][i:last_idx]]\n",
    "            tmp = model_luke.encode( tmp ).detach().numpy()\n",
    "\n",
    "            spt_vector += np.sum(tmp, axis = 0)\n",
    "\n",
    "            try:\n",
    "                category_vectors[category] += np.sum(tmp, axis = 0)\n",
    "                category_counts[category] += last_idx - i\n",
    "            except:\n",
    "                category_vectors[category] = np.sum(tmp, axis = 0)\n",
    "                category_counts[category] = last_idx - i\n",
    "\n",
    "            try:\n",
    "                prefecture_vectors[prefecture] += np.sum(tmp, axis = 0)\n",
    "                prefecture_counts[prefecture] += last_idx - i\n",
    "            except:\n",
    "                prefecture_vectors[prefecture] = np.sum(tmp, axis = 0)\n",
    "                prefecture_counts[prefecture] = last_idx - i\n",
    "            \n",
    "            try:\n",
    "                weighted_category_vectors[category] += np.sum(tmp / len(a[\"reviews\"]), axis = 0)\n",
    "            except:\n",
    "                weighted_category_vectors[category] = np.sum(tmp / len(a[\"reviews\"]), axis = 0)\n",
    "\n",
    "            try:\n",
    "                weighted_prefecture_vectors[prefecture] += np.sum(tmp / len(a[\"reviews\"]), axis = 0)\n",
    "            except:\n",
    "                weighted_prefecture_vectors[prefecture] = np.sum(tmp / len(a[\"reviews\"]), axis = 0)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        spt_vector /= len(a[\"reviews\"])\n",
    "        with open(f\"{target_dir}{name}_{category}_{prefecture}.json\", \"w\") as f:\n",
    "            json.dump({\n",
    "                \"name\" : name,\n",
    "                \"category\" : category,\n",
    "                \"prefecture\" : prefecture,\n",
    "                \"vector\" : spt_vector.tolist()\n",
    "            }, f)\n",
    "        \n",
    "        try:\n",
    "            weighted_category_counts[category] += 1\n",
    "        except:\n",
    "            weighted_category_counts[category] = 1\n",
    "        \n",
    "        try:\n",
    "            weighted_prefecture_counts[prefecture] += 1\n",
    "        except:\n",
    "            weighted_prefecture_counts[prefecture] = 1\n",
    "\n",
    "# 重み付け無しカテゴリ・都道府県ベクトルの保存\n",
    "if not os.path.exists(f\"{target_dir}categories/\"):\n",
    "    os.mkdir(f\"{target_dir}categories/\")\n",
    "\n",
    "for C in category_vectors.keys():\n",
    "    with open(f\"{target_dir}categories/{C}.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"vector\" : (category_vectors[C] / category_counts[C]).tolist(),\n",
    "            \"category\" : C\n",
    "        }, f)\n",
    "\n",
    "if not os.path.exists(f\"{target_dir}prefectures/\"):\n",
    "    os.mkdir(f\"{target_dir}prefectures/\")\n",
    "\n",
    "for P in prefecture_vectors.keys():\n",
    "    with open(f\"{target_dir}prefectures/{P}.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"vector\" : (prefecture_vectors[P] / prefecture_counts[P]).tolist(),\n",
    "            \"prefecture\" : P\n",
    "        }, f)\n",
    "\n",
    "# 重み付け有りカテゴリ・都道府県ベクトルの保存\n",
    "if not os.path.exists(f\"{target_dir}weighted_categories/\"):\n",
    "    os.mkdir(f\"{target_dir}weighted_categories/\")\n",
    "\n",
    "for C in weighted_category_vectors.keys():\n",
    "    with open(f\"{target_dir}weighted_categories/{C}.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"vector\" : (weighted_category_vectors[C] / weighted_category_counts[C]).tolist(),\n",
    "            \"category\" : C\n",
    "        }, f)\n",
    "\n",
    "if not os.path.exists(f\"{target_dir}weighted_prefectures/\"):\n",
    "    os.mkdir(f\"{target_dir}weighted_prefectures/\")\n",
    "\n",
    "for P in weighted_prefecture_vectors.keys():\n",
    "    with open(f\"{target_dir}weighted_prefectures/{P}.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"vector\" : (weighted_prefecture_vectors[P] / weighted_prefecture_counts[P]).tolist(),\n",
    "            \"prefecture\" : P\n",
    "        }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luke_env3_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
